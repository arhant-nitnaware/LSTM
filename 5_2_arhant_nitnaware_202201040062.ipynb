{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 5.2: Sequence Text Prediction using LSTM\n",
        "\n",
        "**Objective:**  \n",
        "To generate next characters/words based on a given input sequence using an LSTM.\n"
      ],
      "metadata": {
        "id": "n8q94CNQIteH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Vmw3gi0BIDC2"
      },
      "outputs": [],
      "source": [
        "#@title 1. Install & Import Libraries\n",
        "# !pip install tensorflow tensorflow-datasets numpy matplotlib\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load & Inspect Data\n",
        "Load the Shakespeare “tiny_shakespeare” text corpus from TensorFlow Datasets.\n"
      ],
      "metadata": {
        "id": "Xkiczz7eIvqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "ds = tfds.load('tiny_shakespeare', split='train')\n",
        "text = ''\n",
        "for example in tfds.as_numpy(ds):\n",
        "    text += example['text'].decode('utf-8')\n",
        "\n",
        "print(text[:500])  # show first 500 characters\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VU7zbN2UIwye",
        "outputId": "14b05cb3-8ceb-44b5-b023-114bb2c19005"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Preprocess: Character-Level Tokenization\n",
        "Build vocabulary mappings from characters to integer IDs.\n"
      ],
      "metadata": {
        "id": "4fP3rpDhIy-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(text))\n",
        "char2idx = {c: i for i, c in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "text_as_int = np.array([char2idx[c] for c in text])\n",
        "print(f'Vocabulary size: {len(vocab)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cVS8m-fIzaU",
        "outputId": "ca91b441-034e-4da8-ff84-7687b7b7d37f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Create Input–Target Sequences\n",
        "Split the integer sequence into overlapping windows of length `seq_length + 1`, then map to `(input, target)` pairs.\n"
      ],
      "metadata": {
        "id": "o0RgoapmI0zF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)\n",
        "\n",
        "def split_input_target(seq):\n",
        "    return seq[:-1], seq[1:]\n",
        "\n",
        "dataset = sequences.map(split_input_target)\n"
      ],
      "metadata": {
        "id": "6uDrZOc1I2Ct"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Batch & Shuffle\n",
        "Prepare final training dataset with shuffling, batching, and prefetching.\n"
      ],
      "metadata": {
        "id": "a7md7NufI3e2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (dataset\n",
        "           .shuffle(BUFFER_SIZE)\n",
        "           .batch(BATCH_SIZE, drop_remainder=True)\n",
        "           .prefetch(tf.data.AUTOTUNE))\n"
      ],
      "metadata": {
        "id": "g_eAv_QtI4ix"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Build the LSTM Model\n",
        "Embedding → Stateful LSTM → Dense output layer.\n"
      ],
      "metadata": {
        "id": "Ks9AJtyxI6DU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the LSTM Model (corrected)\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim),  # removed batch_input_shape\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                         return_sequences=True),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "])\n"
      ],
      "metadata": {
        "id": "IFFzKA8GI65M"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Compile the Model\n",
        "Use Adam optimizer and sparse categorical crossentropy loss.\n"
      ],
      "metadata": {
        "id": "zfv5fr0HI8Lb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "-xKJeaFwI9J4",
        "outputId": "8578bbe5-4a19-4136-db71-4ff52fdbf1ec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Train the Model\n",
        "Train for a fixed number of epochs (e.g. 20).\n"
      ],
      "metadata": {
        "id": "voacIxFAI-X9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "history = model.fit(dataset, epochs=EPOCHS)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sikogm-5JAA2",
        "outputId": "b14b4811-68e1-4873-df4c-e9c02e210509"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 70ms/step - accuracy: 0.1986 - loss: 3.1818\n",
            "Epoch 2/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 71ms/step - accuracy: 0.3966 - loss: 2.0639\n",
            "Epoch 3/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 72ms/step - accuracy: 0.4806 - loss: 1.7544\n",
            "Epoch 4/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 73ms/step - accuracy: 0.5237 - loss: 1.5902\n",
            "Epoch 5/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 72ms/step - accuracy: 0.5512 - loss: 1.4849\n",
            "Epoch 6/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 71ms/step - accuracy: 0.5666 - loss: 1.4237\n",
            "Epoch 7/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 70ms/step - accuracy: 0.5783 - loss: 1.3760\n",
            "Epoch 8/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 71ms/step - accuracy: 0.5904 - loss: 1.3300\n",
            "Epoch 9/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 72ms/step - accuracy: 0.5993 - loss: 1.2969\n",
            "Epoch 10/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 72ms/step - accuracy: 0.6070 - loss: 1.2640\n",
            "Epoch 11/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 72ms/step - accuracy: 0.6159 - loss: 1.2332\n",
            "Epoch 12/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 71ms/step - accuracy: 0.6237 - loss: 1.2040\n",
            "Epoch 13/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 71ms/step - accuracy: 0.6306 - loss: 1.1773\n",
            "Epoch 14/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 72ms/step - accuracy: 0.6386 - loss: 1.1503\n",
            "Epoch 15/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 72ms/step - accuracy: 0.6485 - loss: 1.1178\n",
            "Epoch 16/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 71ms/step - accuracy: 0.6561 - loss: 1.0909\n",
            "Epoch 17/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 71ms/step - accuracy: 0.6680 - loss: 1.0548\n",
            "Epoch 18/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 71ms/step - accuracy: 0.6783 - loss: 1.0230\n",
            "Epoch 19/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 71ms/step - accuracy: 0.6892 - loss: 0.9882\n",
            "Epoch 20/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 71ms/step - accuracy: 0.7028 - loss: 0.9471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Plot Training Loss & Accuracy\n",
        "Visualize how loss and accuracy evolve over epochs.\n",
        "plt.figure(figsize=(12,4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1X3Bp7DZJDyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TEXT GENERATION CELL ---\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def generate_text(model, start_string, num_generate=300, temperature=1.0):\n",
        "    # Convert start_string to integer IDs\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)# shape (1, len(start_string))\n",
        "\n",
        "    generated_chars = []\n",
        "    #model.reset_states()\n",
        "\n",
        "    for _ in range(num_generate):\n",
        "        # Predict next character\n",
        "        preds = model(input_eval)                            # (1, seq_len, vocab_size)\n",
        "        preds = preds[:, -1, :]                              # (1, vocab_size)\n",
        "        preds = preds / temperature\n",
        "        predicted_id = tf.random.categorical(preds, num_samples=1)[0,0].numpy()\n",
        "\n",
        "        # Append and update input\n",
        "        generated_chars.append(idx2char[predicted_id])\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)       # feed back the last prediction\n",
        "\n",
        "    return start_string + ''.join(generated_chars)\n",
        "\n",
        "# Example usage:\n",
        "print(generate_text(model, start_string=\"ROMEO: \", num_generate=500, temperature=0.5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq7fBy8JJCp_",
        "outputId": "8a0f04f0-718b-4ced-8164-3b388794aa38"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO: CFLG3N;!H'DM3!:KHIIJ :\n",
            "MHFMK.!A.J N'$$D.$H\n",
            "GO:IL&,!E-I&LMBL;ALGJJ$\n",
            "KKAG3DGN'. !FA.BJN:DALM!OBMM,M:?ILHMHEL N\n",
            "!GI.&E K& G!3N;?FEG,L,, G\n",
            "&E?BJ?$!B-EJFHIC\n",
            ";BEAILH;\n",
            "LLC$;:L-H?-N.K$$?CH.KGJ;C$N$,A,ML3G!GEG$H:OLKG$HF3&IL:FOJH-BAF.:!;.$HO:HN$N\n",
            "HLDEFJ?GKEBLLIE&HM \n",
            "'$!!;:ACBEFHJ'G.NA\n",
            "G&!IH:3,.-GA?LHGJMJ',M.&E??N'H, D?GGEIIK\n",
            "D;.F,&CE$F&AHB?'!C?'N3,!.O.; GEI-FKKLC3.ONO,$\n",
            "NOBONOAOJEHN!ELDJFF3CJHB&,!L?J,?!M'DCEL!FF!MA ADAMD-,G&$B&N 'AK:FE$HN$;?OALJ:;GBF:HA! 3IC&D-N!MNLAML'3!!FI$&H&3ILG-&DCOK,\n",
            "C'EI:NOBMA A$!$\n"
          ]
        }
      ]
    }
  ]
}